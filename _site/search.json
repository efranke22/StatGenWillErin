{
  "articles": [
    {
      "path": "analysisR.html",
      "title": "Data Analysis",
      "description": "More on multiple hypothesis testing on how to do it in RStudio with sample data\n",
      "author": [],
      "contents": "\nThis page will go through an example of what the multiple hypothesis testing procedure looks like for a sample set of data. Before reviewing this section, please visit Data to learn more about the dataset we are using the cleaning steps necessary to perform this analysis.\n\n\n\nThe limit of Bonferroni\nAs discussed in the Hypothesis Testing Background section, multiple hypothesis testing is a necessary part of statistical analyses. It helps us determine the correct threshold for selecting SNPs to devote further time and resources to studying as using the standard 0.05 threshold would lead to falsely asserting relationships between a SNP and the trait of interest far too often (too many Type I errors).\nWhile Bonferroni is a great way to get an approximate threshold for a given number of SNPs, it is flawed because it treats all SNPs as independent of one another. In reality, SNPs are correlated with each other and the extent of that correlation depends on the data. This is known as the concept of linkage disequalibrium, which as stated in Science Direct is the idea that two markers in close physical proximity are correlated in a population and are in association more than would be expected with random assortment. Essentially, SNPs next to each other are much more similar than SNPs far away from each other.\nWe can show this concept of correlation with our data. To do this, we will use the SnpMatrix in which our data is stored. As mentioned in the Data section, each row is one of the 165 members of this study, and each column is one of our 1,457,897 SNPs.\n\n\nhapmap$genotypes\n\nA SnpMatrix with  165 rows and  1457897 columns\nRow names:  NA06989 ... NA12865 \nCol names:  rs2185539 ... rs1973881 \n\n1,457,897 SNPs is a big number, and it would be hard to show the correlation when all of them. As a result, we just show the linkage disequalibrium matrix below for the first 100 polymorphic SNPs on chromosome 1. The diagonal line moving from the top left corner of the plot to the bottom right corner represents each SNP’s correlation with itself, and therefore is filled in as white square. What you can notice from this plot is that SNPs that are nearby each other (bordering the white diagonal line) are often represented in orange, meaning they are highly correlated.\n\n\nchr1_100 <- hapmap$genotypes[1:165, 1:119]\ncolor.pal <- natparks.pals(\"Acadia\", 10)\n\n#get monomorphic SNPs only\nmaf_chr1_100 <- col.summary(chr1_100)$MAF\nmono <- which(maf_chr1_100 == 0)\n\n# calculate LD on polymorphic SNPs only\nhapmap.ld.nomono <- ld(chr1_100[,-mono], depth = 118-length(mono), stats = \"R.squared\", symmetric = TRUE)\n\n# plot \nimage(hapmap.ld.nomono, lwd = 0, cuts = 9, col.regions = color.pal, colorkey = TRUE)\n\n\n\nWhile the first 100 polymorphic SNPs from this HapMap dataset have the linkage disequilibrium matrix shown above, if we were to look at another dataset it might look completely different. For example, the linkage disequilibrium matrix for the first 100 SNPs from a dataset from Rbloggers looks like this:\n\n\n\nThe reason we are showing these correlation matrices is to demonstrate that different studies have different levels of correlation in the data. The more similar SNPs are, the fewer hypothesis tests effectively conducted and thus the higher the threshold can be. Therefore, even with the same number of SNPs in two different studies, thresholds can vary quite a bit. The method to determine the right threshold for your data therefore must be done using simulation.\nDetermining a threshold with simulation in RStudio\nThe process for determining a threshold is as follows:\nSimulate a null trait, meaning a trait not associated with any of the SNPs.\nRun GWAS to test the association between the simulated null trait and each SNP in our dataset. After that record the smallest p-value from this GWAS.\nRepeat steps 1 and 2 many times, typically 1,000-10,000 times in professional genetic studies.\nLook at the p-values saved from those simulation replicates. Sort them from smallest to largest and find the number at which 5% (desired FWER) of p-values are smaller than that number. This is the significance threshold.\nLet’s break this down step by step.\nStep One\nThe first step is simulate a null trait, meaning a trait not associated with any SNPs. We call this trait y, and generate 165 data points with a mean of 0 and standard deviation of 1.\n\n\ny = rnorm(n = 165, mean = 0, sd = 1)\n\n\nStep Two\nNext, we run a GWAS to test the association between the simulated null trait y and each SNP in our dataset. To do this, we use marginal regression and fit a model with the SNP as the single independent variable and the trait of interest as the dependent variable. Looking at our first three SNPs, the models can be created as shown in the code chunk below. If you don’t have X.clean in your R environment, go run the code in the Data section.\n\n\nset.seed(494)\nsnp1mod <- lm(y ~ X.clean[,1])\nsnp2mod <- lm(y ~ X.clean[,2])\nsnp3mod <- lm(y ~ X.clean[,3])\n\ntidy(snp1mod)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    -0.757     0.984    -0.769   0.443\n2 X.clean[, 1]    0.386     0.494     0.782   0.435\n\nEach of these models produces an estimate for the coefficient on the SNP. For example, the coefficient for snp1mod is 0.12. The way we might interpret this is that for every additional minor allele (G for example) that you carry at that position, the trait of interest changes by about 0.12 units. If the trait we were measuring was height, we would expect your height to increase about 0.12 inches for every additional minor allele (a value of either 0, 1, or 2) at SNP 1.\nObviously, we cannot do the process above by hand for over one million SNPs (which is necessary to complete 1 GWAS). However, we can do this with a loop! This code loops through each of the SNPs, fitting a linear regression model at each one. For each model, we record the estimates (betas), standard errors (ses), test statistics (tstats) and p-values (pvals) for the coefficient of interest, which is the slope.\nWarning: this code may take 30-60 minutes to run. Feel free to read over the rest of this step but skip running any code.\n\n\n# set up empty vectors for storing results\nbetas <- c()\nses <- c()\ntstats <- c()\npvals <- c()\n\n# loop through all SNPs\nfor(i in 1:ncol(X.clean)){ \n  # fit model\n  mod <- lm(y ~ X.clean[,i])\n  # get coefficient information\n  coefinfo <- tidy(mod)\n  # record estimate, SE, test stat, and p-value\n  betas[i] <- coefinfo$estimate[2]\n  ses[i] <- coefinfo$std.error[2]\n  tstats[i] <- coefinfo$statistic[2]\n  pvals[i] <- coefinfo$p.value[2]\n}\n\n\nNext we record add our results to our map.clean data frame that contains information about each SNP:\n\n\nall.results <- map.clean %>%\n  mutate(Estimate = betas,\n         Std.Error = ses,\n         Test.Statistic = tstats,\n         P.Value = pvals)\n\nhead(all.results)\n\n\n\nWe then arrange the p-values from smallest to largest and record the smallest one. In this trial, the smallest p-value was \\(4 \\times 10^{-7}\\).\nIf this procedure was done with our trait of interest, an additional step to complete this GWAS might be to create a Manhattan plot which shows the p-values of all SNPs in our dataset. If a p-value is less than a threshold we have set, it should stand out on the plot and prompt further analysis. We will talk more about these Manhattan plots later on, once we have completed multiple hypothesis testing and determined a threshold.\nStep 3\nStep 3 is to repeat steps 1 and 2 many times, typically 1,000-10,000 times in professional genetic studies. But wait - did you run the GWAS above on your computer? If so, it probably took 30 - 60 minutes. In order to complete even 1000 replications at 30 minutes, it would take about 20.83 days on a single computer (we tested this and that number was accurate). 10,000 replications would take about 7 months, which we did not test (thankfully). As a result, this process is not feasible in RStudio! However, we will put the code below for 1000 replications in case you are tempted.\nOne thing this code does do is utilize the function mclapply() from the parallel package. This package will work to utilize all cores of your computer to the run code. The computer this code was run on only has two cores, but for computers with 8-10 cores this package could make a significant difference in computational time (perhaps on the level of 8-10x faster if nothing else is running in the background). However, even 8-10x faster will still result in it taking at least a few days to determine a threshold with 1000 replications.\n\n\ndim(X.clean)\ndo_one_sim<- function(i){\n  \n  # simulate null trait\n  y <- rnorm(n = 165, mean = 0, sd = 1) # n= number people in study\n  \n  # implement GWAS\n  pvals <- c()\n  for(i in 1:1283751){ #number SNPs in X.clean\n    mod <- lm(y ~ snp[,i])\n    pvals[i] <- tidy(mod)$p.value[2]\n  }\n  # record smallest p-value\n  min(pvals)\n}\n\n# Do 1000 replications with mclapply()\nset.seed(494)\nsimresmclapply <- mclapply(1:1000, do_one_sim, mc.cores = 2) \n\n\nStep 4\nIf you for some reason decided to run the code in Step 3, you could run the following code chunk to get the threshold for the family wise error rate of 5%. This is the significance threshold!\n\n\n# Print the 0.05 quantile \nquantile(simresmclapply %>% as.data.frame(), 0.05)\n\n\nA computationally efficient solution\nIn order to avoiding spending days of times and heavily comprising computer efficiency, we will demonstrate how to get threshold in PLINK. To learn more about PLINK and how to use it, check out the Hypothesis Testing in PLINK tab.\n\n\n\n",
      "last_modified": "2022-12-07T18:52:48-06:00"
    },
    {
      "path": "data.html",
      "title": "HapMap Data",
      "description": "This page explains information on the data context and cleaning steps necessary to run GWAS and multiple hypothesis testing procedures in RStudio.\n",
      "author": [],
      "contents": "\nIn the Data Analysis and Hypothesis Testing in PLINK tabs of this site, we will explain how to do a GWAS and determine a threshold for a set of genetic data. To follow along, download the 1_QC_GWAS.zip file from this page. This data comes from the International HapMap project (also known as “HapMap”). For more information on the data and project, check out this tutorial.\nData Loading and Organization\nThe following code chunks outline the steps of importing the genetic data.\nIf you have not installed the snpStats package, install it in the console by running the following code chunk.\n\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"snpStats\")\n\n\nLoad libraries:\n\n\nlibrary(snpStats)\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(NatParksPalettes)\nlibrary(parallel)\nlibrary(GGally)     \n\n\nLoad the data, using the correct directory of where you put the HapMap_3_r3_1.fam, HapMap_3_r3_1.bim, and HapMap_3_r3_1.bed files from the 1_QC_GWAS.zip folder. This process uses read.plink(), which reads a genotype matrix, information on the study’s individuals, and information on the SNPs.\n\n\nfam <- 'hapmapData/HapMap_3_r3_1.fam'\nbim <- 'hapmapData/HapMap_3_r3_1.bim'\nbed <- 'hapmapData/HapMap_3_r3_1.bed'\n\nhapmap <- read.plink(bed, bim, fam)\n\n\nUnderstanding the Data\nFirst, get information about the genotype data. We have 165 individuals and 1,457,897 SNPs.\n\n\nhapmap$genotypes\n\nA SnpMatrix with  165 rows and  1457897 columns\nRow names:  NA06989 ... NA12865 \nCol names:  rs2185539 ... rs1973881 \n\nNext, look at the information we have on the individuals in the study. Theoretically, this gives information on family relationships with pedigree, father, and mother, but the father and mother variables contain only missing values. We also have information on the individual’s binary sex, with 1 representing male and 2 female. The affected column represents if the individual had the trait of interest or not, but there are many missing values in this column.\n\n\nhead(hapmap$fam)\n\n        pedigree  member  father  mother sex affected\nNA06989     1328 NA06989    <NA>    <NA>   2        2\nNA11891     1377 NA11891    <NA>    <NA>   1        2\nNA11843     1349 NA11843    <NA>    <NA>   1        1\nNA12341     1330 NA12341    <NA>    <NA>   2        2\nNA12739     1444 NA12739 NA12748 NA12749   1       NA\nNA10850     1344 NA10850    <NA> NA12058   2       NA\n\nFinally, we can look at the information we have on each SNP. This tells us a few things:\nchromosome is the number chromosome (typically 1-23) that the SNP is located on.1 is the largest chromosome (most SNPs) and chromosome size typically decreases from there.\n\nsnp.name is the name of the SNP\ncM stands for centiMorgans, which is a unit for genetic distance. It represents an estimate of how far SNPs are from one another along the genome.\nposition tells us the base pair position of the SNP, with position being being the first nucleotide in our DNA sequence.This number restarts from 1 at each chromosome.\n\nallele.1 is one of the alleles at this SNP, here the minor allele.\nallele.2 is the other allele at this SNP, here the major allele.\n\n\nhead(hapmap$map)\n\n           chromosome   snp.name cM position allele.1 allele.2\nrs2185539           1  rs2185539 NA   556738        T        C\nrs11510103          1 rs11510103 NA   557616        G        A\nrs11240767          1 rs11240767 NA   718814        T        C\nrs3131972           1  rs3131972 NA   742584        A        G\nrs3131969           1  rs3131969 NA   744045        A        G\nrs1048488           1  rs1048488 NA   750775        C        T\n\nData Cleaning\nOne useful piece of information not contained in the data is the minor allele frequency (MAF). This represents the frequency of the minor allele in the dataset. We can add this to our snpMatrix using the snpstats package and add MAF to map, our dataframe that gives us SNP information.\n\n\n#calculate MAF\nmaf <- col.summary(hapmap$genotypes)$MAF\n\n# add new MAF variable to map\nmap <- hapmap$map %>%\n  mutate(MAF = maf)\nhead(map)\n\n           chromosome   snp.name cM position allele.1 allele.2\nrs2185539           1  rs2185539 NA   556738        T        C\nrs11510103          1 rs11510103 NA   557616        G        A\nrs11240767          1 rs11240767 NA   718814        T        C\nrs3131972           1  rs3131972 NA   742584        A        G\nrs3131969           1  rs3131969 NA   744045        A        G\nrs1048488           1  rs1048488 NA   750775        C        T\n                  MAF\nrs2185539  0.00000000\nrs11510103 0.00621118\nrs11240767 0.00000000\nrs3131972  0.15757576\nrs3131969  0.13030303\nrs1048488  0.15853659\n\nJust looking at the MAF for the first six SNPs in our data, we see that in some cases the minor allele frequency is 0. This means that the SNP is monomorphic - everyone in the dataset has the same genotype at these positions. We will remove these monomorphic SNPs - if everyone has the same alleles at a SNP, there is no variation and we cannot find an association between the minor allele and the trait.\nIt can also help to think about why we remove SNPs with a MAF of 0 in a mathematical way. If we are trying to fit a line between the trait of interest and SNP 1, we could model this in the following formats, with linear regression listed first and matrix notation second.\n\\[E[Y|\\text{SNP1}] = \\beta_0 + \\beta1 \\text{SNP1}\\]\n\\[E[\\bf{y}|\\bf{X}] = \\boldsymbol{\\beta} X\\]\nFurther exploring the matrix format, it would look like this:\n\\[X\\boldsymbol{\\beta} = \\begin{bmatrix}\n1 & 0 \\\\\n1 & 0 \\\\\n. & . \\\\\n. & . \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0\\\\\n\\beta_1 \\\\\n\\end{bmatrix}\\]\nExecuting this multiplication, we just get \\(1 * \\beta_0 = 0\\). The is problematic because we have linear dependence. You can get the column of minor allele counts by multiplying the intercept column by 0 - in other words, the minor allele count column is a linear combination of the intercept column. This makes our design matrix not be full rank, making \\(X^TX\\) not invertible and the least squares estimator not defined.\nGiven all these reasons, we remove SNPs with a MAF of 0 using the code below.\n\n\nmap <- map %>%\n  filter(maf >0 )\n\ndim(map)\n\n[1] 1283751       7\n\nAfter filtering, we have 1,283,751 SNPs remaining. Therefore, we removed 174,146 monomorphic SNPs.\nBefore moving on, we must complete one final data cleaning step. The snpstats package uses a format in which genotypes are coded as 01, 02, and 03, with 00 representing missing values.\n\n\nhapmap$genotypes@.Data[1:5,1:5]\n\n        rs2185539 rs11510103 rs11240767 rs3131972 rs3131969\nNA06989        03         03         03        02        02\nNA11891        03         03         03        02        03\nNA11843        03         03         03        03        03\nNA12341        03         03         03        02        02\nNA12739        03         03         03        03        03\n\nWe will convert this to a 0, 1, and 2 format. Now the matrix represents the number of major alleles each person has at each SNP.\n\n\nX <- as(hapmap$genotypes, \"numeric\")\nX[1:5, 1:5]\n\n        rs2185539 rs11510103 rs11240767 rs3131972 rs3131969\nNA06989         2          2          2         1         1\nNA11891         2          2          2         1         2\nNA11843         2          2          2         2         2\nNA12341         2          2          2         1         1\nNA12739         2          2          2         2         2\n\nCreate X.clean by removing the monomorphic SNPs from X.\n\n\nmap.clean <- map %>%\n  filter(MAF >0)\nX.clean <- X[,colnames(X) %in% map.clean$snp.name]\n\n\nThe data is now clean and ready to be used. Check out the Data Analysis next!\n\n\n\n",
      "last_modified": "2022-12-07T16:35:07-06:00"
    },
    {
      "path": "hapmapAnalysis.html",
      "title": "A final analysis of our HapMap data",
      "description": "How we combined our knowledge of multiple hypothesis testing and PLINK results to determine an appropriate significance threshold for our HapMap dataset\n",
      "author": [],
      "contents": "\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(snpStats)\nlibrary(NatParksPalettes)\n\n\nLoad hapmap data\nCreate a null trait and write a file to the plink data folder.\n\n\nfam <- 'plinkData/HapMap_3_r3_1.fam'\nbim <- 'plinkData/HapMap_3_r3_1.bim'\nbed <- 'plinkData/HapMap_3_r3_1.bed'\n\nhapmap <- read.plink(bed, bim, fam)\n\n\n\n\nmanhattan_data <- cbind(hapmap$fam %>% select(1:2), trait = rnorm(n = 165, mean = 0, sd = 1))\nwrite_delim(manhattan_data, \"plinkData/manhattandata\")\n\n\nUse command to run GWAS in PLINK, accounting for correlated SNPs\n- ./plink –bfile HapMap_3_r3_1 –assoc –adjust –pheno manhattandata –out as2\nRead in results from PLINK and create Manhattan plot\n\n\nresults <- read_table(\"plinkData/as2.qassoc.adjusted\")\n\nresults_with_position <- results %>%\n  mutate(CHR = as.integer(CHR)) %>%\n  left_join(hapmap$map %>%\n              select(snp.name, position, chromosome), by = c(\"SNP\" = \"snp.name\", \"CHR\" = \"chromosome\"))\n\n\n\n\nresults_with_position %>%\n  mutate(minuslogp = -log10(GC),\n         CHR = as.factor(CHR)) %>%\n  ggplot(aes(x = CHR, y = minuslogp, group = interaction(CHR, position), color = CHR)) + \n  geom_point(position = position_dodge(0.8)) + \n  labs(x = 'chromosome', y = expression(paste('-log'[10],'(p-value)')))+\n  theme_classic()+\n  scale_color_manual(values=natparks.pals(\"DeathValley\",24))+\n  theme(legend.position = \"none\")\n\n\n\nComplete replications\nSimulation based approach. Approximately 14.45 minutes to run GWAS in plink, then 3 minutes 20 seconds to load files into R.\n\n\ncreate_quantitative_trait <- function(i){\n  y <- rnorm(n = 165, mean = 0, sd = 1) \n}\n\ntraits <- as.data.frame(replicate(1000, create_quantitative_trait()))\n\ntraits_identified <- cbind(hapmap$fam %>%\n        select(1:2), traits)\n\nwrite_delim(traits_identified, \"plinkData/traits_identified\")\n\n\n./plink –bfile HapMap_3_r3_1 –assoc –pheno traits_identified –all-pheno –pfilter 1e-3\n\n\ndataFiles <- lapply(Sys.glob(\"plinkData/plink.P*.qassoc\"), read_table)\n\npvalues <- sapply(dataFiles, function(x) min(x$P, na.rm=TRUE))\n\nas.data.frame(pvalues) %>%\n  ggplot(aes(x=pvalues))+\n  geom_density(fill = \"cadetblue\")+\n  theme_classic()+\n  annotate(geom = \"text\", color = \"red\", x = 1e-05, y = 250000, label = \"0.05 quantile:\\n7.31495e-08\", family = \"mono\", cex = 3)+\n  geom_vline(xintercept = 7.31495e-08, color = \"red\", linetype = \"dashed\")+\n  labs(x=\"P-values\", y = \"Density\", title = \"Distribution of minimum p-values for 1000 replications\")+\n  geom_curve(aes(x = 1e-05, y = 270000, xend = 1e-06, yend = 350000), \n             arrow = arrow(length = unit(0.03, \"npc\")), curvature = 0.3, color = \"red\")+\n  theme(plot.title.position = \"plot\", \n        plot.title = element_text(family = \"mono\"), \n        axis.title = element_text(family = \"mono\"), \n        axis.text = element_text(family = \"mono\"))\n\n\nquantile(pvalues, 0.05)\n\n         5% \n7.31495e-08 \n\n\n\n\n",
      "last_modified": "2022-11-17T15:27:15-06:00"
    },
    {
      "path": "HapMapPlink.html",
      "title": "Multiple Hypothesis Testing in PLINK",
      "description": "How to use a more computationally efficient software to determine a threshold\n",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-12-07T16:33:59-06:00"
    },
    {
      "path": "index.html",
      "title": "An Extension of Multiple Hypothesis Testing in Statistical Genetics",
      "description": "A project by Will Brazgel and Erin Franke exploring multiple hypothesis testing and using PLINK and R to efficiently execute it on genetic data\n",
      "author": [],
      "contents": "\nIntroduce website structure and motivation\n\n\n\n",
      "last_modified": "2022-12-07T18:09:19-06:00"
    },
    {
      "path": "multipletesting.html",
      "title": "Multiple Hypothesis Testing",
      "description": "An explanation of the complexities to making statistically significant conclusions when working with genetic data \n",
      "author": [],
      "contents": "\nGenome Wide Association Studies\nIf we compare any two human genomes, they are nearly identical. However, places where DNA sequences differ are known as genetic variants. There are multiple types of genetic variants, but our work is primarily focused on single nucleotide variants (SNVs).\nSNVs : DNA variation that occurs when a single nucleotide in the genome sequence is altered (A vs G at a single position).\n\nGenetic Variant Example\nGenome Wide Association Studies can aid in the determination of which genetic variants are associated with an illness or trait of interest.\nIn order to make statements on whether or not a genetic variant is associated with the trait of interest, we utilize hypothesis testing.\nHypothesis Testing Review\n\n\n\n",
      "last_modified": "2022-12-07T18:20:26-06:00"
    }
  ],
  "collections": []
}
